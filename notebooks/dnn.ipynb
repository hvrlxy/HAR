{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.append(os.path.dirname(os.path.abspath(Path.cwd())))\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, make_scorer\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from scipy import stats\n",
    "import joblib\n",
    "import shap\n",
    "import seaborn as sns\n",
    "import src.data_prep.split_data as sd\n",
    "import src.data_prep.preprocess as pp\n",
    "import src.data_prep.eda as eda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create raw time series dataset\n",
    "\n",
    "In the (train_basic_data)[./train_basic_data.ipynb] notebook, we have divide our accelerometer data into different intervals with 50% overlap, calculating the basic statistics of the time series (such as std, max, min, mean, ...) and fit some classical machine learning model to classify different activities. However, since our dataset is properly clean and collected in an experiment setting, with the transition period removed, if we were to use such model in real life, we might not be able to get a good performance.\n",
    "\n",
    "In this notebook, we will feed the raw time series data collected from the sensors to some deep learning model, and test their accuracy in classifying different labeled activities. First, we need to prepare our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "subject_df = pp.load_dataset(1)\n",
    "# split data\n",
    "intervals = sd.split_data_by_interval(subject_df)\n",
    "intervals.pop()\n",
    "# get intervals activities\n",
    "y = [list(activity[\"activity\"])[0] for activity in intervals]\n",
    "# get intervals matrix\n",
    "X = [activity[[\"x\", 'y', 'z']].T.to_numpy() for activity in intervals]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline model\n",
    "We will set up a simple multi-layer perceptron as our baseline model for this task. Since the MLP is sensitive to feature scaling, we will scale our data using the standard scaler:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1502 1667 1611 1601 1643 1604 1640 1607 1546 1529 1637 1596 1590 1601\n",
      "  1542 1598 1511 1555 1508 1580 1627 1592 1634 1638 1593 1542 1601 1613\n",
      "  1644 1642 1605 1586 1577 1598 1561 1628 1694 1627 1598 1612 1630 1609\n",
      "  1600 1608 1612 1605 1640 1610 1633 1573 1568 1576 1599 1620 1654 1637\n",
      "  1603 1605 1620 1616 1611 1597 1587 1566 1497 1455 1499 1556 1567 1568\n",
      "  1533 1519 1586 1618 1630 1646 1638 1595 1625 1645 1673 1607 1609 1613\n",
      "  1670 1663 1635 1649 1726 1778 1718 1724 1630 1664 1706 1691 1682 1690\n",
      "  1735 1665 1643 1624 1641 1681 1651 1632 1632 1648 1643 1638 1586 1578\n",
      "  1559 1635 1671 1687 1704 1757 1806 1814 1839 1844 1929 1806 1782 1775\n",
      "  1855 1893 1876 1950 1811 1876 1889 1883 1902 1937 1978 2026 2066 2106\n",
      "  2123 2052 2006 2028 2034 1985 1997 2069 2081 2105 2131 2098 2127 2175\n",
      "  2029 2191 2182 2139 2151 2168 2156 2189 2238 2183 2100 1985 2001 2061\n",
      "  2102 2085 2224 2227 2227 2195 2209 2092 2185 2275 2289 2356 2190 2092\n",
      "  2112 2143 2176 2053 2274 2117 2131 2076 2115 1979 2107 2148 2050 2033\n",
      "  2133 2110 2132 2090 2059 2029 1880 1895 1911 1777 1744 1681 1822 1956\n",
      "  2005 1986 2007 1973 1828 1872 1999 1956 1887 1883 1902 2009 1948 1914\n",
      "  1982 2009 1935 1899 1963 1965 1915 1980 2018 1857 2009 1961 2000 2062\n",
      "  2054 2118 1834 1889 1987 1834 1915 2051 2081 2021 1974 1999 1912 1802\n",
      "  1980 2067 1966 1939 1992 2007 2014 1988]\n",
      " [2215 2072 1957 1939 1965 1959 1829 1910 2045 2049 1978 2046 2006 1966\n",
      "  2003 2027 2258 1980 2468 1697 2073 2130 2088 2102 2123 2133 2015 1938\n",
      "  1974 1933 1925 1998 2032 1980 1942 1935 1965 1922 1950 1952 1958 1973\n",
      "  1983 1969 1957 1943 1917 1949 1930 1868 1944 2217 2045 1981 2069 2019\n",
      "  1992 2008 2001 2016 2019 1999 1999 1953 1966 2072 2090 2029 1963 1999\n",
      "  2049 2005 2089 2045 1974 2030 2077 2105 2117 2049 2067 2099 2099 2173\n",
      "  2147 2014 2120 2123 2203 2143 2102 2101 2359 2241 2277 2206 2172 2203\n",
      "  2343 2225 2243 2231 2254 2243 2188 2226 2227 2226 2242 2284 2279 2309\n",
      "  2263 2300 2221 2237 2222 2251 2220 2189 2139 2134 2409 2043 2541 2184\n",
      "  2142 2221 2244 2319 2259 2298 2297 2295 2284 2275 2290 2295 2307 2322\n",
      "  2323 2291 2291 2332 2347 2302 2323 2334 2327 2294 2267 2254 2277 2267\n",
      "  2174 2211 2288 2283 2329 2339 2375 2348 2314 2316 2323 2367 2228 2233\n",
      "  2293 2351 2324 2313 2303 2282 2315 2147 2186 2355 2385 2325 2262 2279\n",
      "  2286 2373 2346 2279 2424 2183 2476 2339 2311 2430 2506 2366 2320 2394\n",
      "  2381 2343 2196 2329 2360 2243 2312 2259 2225 2402 2405 2471 2426 2470\n",
      "  2381 2407 2339 2359 2355 2318 2335 2386 2375 2373 2327 2267 2323 2361\n",
      "  2391 2393 2361 2298 2323 2389 2395 2324 2514 2298 2306 2316 2362 2369\n",
      "  2342 2305 2340 2336 2311 2352 2313 2295 2309 2343 2378 2441 2447 2404\n",
      "  2308 2254 2289 2369 2381 2364 2395 2411]\n",
      " [2153 2047 1906 1831 1879 1921 1940 1910 1910 1972 1945 1866 1978 1957\n",
      "  1959 1941 1983 2023 1934 2005 1992 2063 1991 1916 1948 2034 2042 1936\n",
      "  2000 2046 2011 2066 2108 2066 2092 2142 2052 2081 2117 2075 2024 2005\n",
      "  2014 2024 2019 2018 2037 2077 2076 2058 1959 2059 2154 2168 2090 2160\n",
      "  2108 2075 2037 2052 2149 2130 2051 1993 2005 2105 2172 2085 2087 2134\n",
      "  2034 2062 2034 2002 2067 2129 2075 2094 2124 2086 2192 2073 2060 2108\n",
      "  2079 2171 2209 2034 2005 1946 2012 2309 1947 2064 1986 1994 2019 1986\n",
      "  2002 1897 1976 1969 1993 1949 1951 1956 1990 1953 1955 1966 1882 1748\n",
      "  1978 2010 1918 1771 1758 1849 1794 1827 1882 1929 2739 1799 2169 1935\n",
      "  1835 1756 1747 1671 1713 1680 1644 1717 1773 1780 1806 1821 1828 1826\n",
      "  1815 1851 1840 1749 1709 1755 1735 1721 1775 1825 1858 1879 1830 1800\n",
      "  1743 1820 1802 1824 1898 2014 2053 1966 1917 1940 1973 1966 1669 1707\n",
      "  1915 2013 1999 2012 2020 2108 2050 2033 2155 2239 2032 1991 1912 1960\n",
      "  2002 2000 2002 2062 1944 2107 1990 1945 1942 1943 1852 1979 1910 1986\n",
      "  1935 1943 2021 2127 2217 2032 2130 2209 2248 2269 2218 2331 2282 2211\n",
      "  2140 2131 2141 2219 2293 2344 2249 2131 2121 2102 2195 2300 2300 2231\n",
      "  2129 2071 2119 2303 2372 2240 2176 2067 2027 2152 2345 2328 2103 1995\n",
      "  2096 2204 2249 2242 2222 2215 2149 2207 2270 2287 2194 2067 1983 2038\n",
      "  2216 2386 2343 2160 2143 2207 2198 2152]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "transform() missing 1 required positional argument: 'X'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/tz/3b9b4njn3xv8fpgh2m4299940000gn/T/ipykernel_64346/4074872824.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# scale the data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: transform() missing 1 required positional argument: 'X'"
     ]
    }
   ],
   "source": [
    "# scale the data\n",
    "X = StandardScaler.transform(X) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
